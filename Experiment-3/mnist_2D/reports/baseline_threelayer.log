2022-03-08 22:51:38,025 Train loader size: 188, Validation loader size: 47, Test loader size: 40
2022-03-08 22:51:47,432 Epoch 0: Training Loss 420.3175456523895
2022-03-08 22:51:56,557 Epoch 1: Training Loss 281.21508824825287
2022-03-08 22:52:05,671 Epoch 2: Training Loss 140.53431805968285
2022-03-08 22:52:14,775 Epoch 3: Training Loss 99.02770897746086
2022-03-08 22:52:23,883 Epoch 4: Training Loss 83.37447226047516
2022-03-08 22:52:32,989 Epoch 5: Training Loss 75.24046379327774
2022-03-08 22:52:42,090 Epoch 6: Training Loss 70.25725683569908
2022-03-08 22:52:51,196 Epoch 7: Training Loss 66.94871407747269
2022-03-08 22:53:00,300 Epoch 8: Training Loss 64.59392367303371
2022-03-08 22:53:09,408 Epoch 9: Training Loss 62.78506751358509
2022-03-08 22:53:18,535 Epoch 10: Training Loss 61.31949508190155
2022-03-08 22:53:27,732 Epoch 11: Training Loss 60.266522631049156
2022-03-08 22:53:36,841 Epoch 12: Training Loss 59.212093979120255
2022-03-08 22:53:45,942 Epoch 13: Training Loss 58.345735400915146
2022-03-08 22:53:55,052 Epoch 14: Training Loss 57.68605937063694
2022-03-08 22:54:04,159 Epoch 15: Training Loss 57.04842655360699
2022-03-08 22:54:13,269 Epoch 16: Training Loss 56.45407246053219
2022-03-08 22:54:22,366 Epoch 17: Training Loss 55.96564853191376
2022-03-08 22:54:31,467 Epoch 18: Training Loss 55.54308806359768
2022-03-08 22:54:40,568 Epoch 19: Training Loss 55.14043487608433
2022-03-08 22:54:40,569 
RESULTS ON TEST DATA:
2022-03-08 22:54:41,893 	     precision: 0.9193
2022-03-08 22:54:41,893 	        recall: 0.9177
2022-03-08 22:54:41,893 	            F1: 0.9156
2022-03-08 22:54:41,893 	      accuracy: 0.9185
