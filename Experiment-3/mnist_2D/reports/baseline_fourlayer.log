2022-03-08 22:54:55,273 Train loader size: 188, Validation loader size: 47, Test loader size: 40
2022-03-08 22:55:04,695 Epoch 0: Training Loss 433.11290526390076
2022-03-08 22:55:14,058 Epoch 1: Training Loss 429.56103134155273
2022-03-08 22:55:23,419 Epoch 2: Training Loss 338.0286034345627
2022-03-08 22:55:32,773 Epoch 3: Training Loss 182.86785072088242
2022-03-08 22:55:42,122 Epoch 4: Training Loss 129.44500294327736
2022-03-08 22:55:51,467 Epoch 5: Training Loss 109.89007511734962
2022-03-08 22:56:00,813 Epoch 6: Training Loss 99.26439091563225
2022-03-08 22:56:10,169 Epoch 7: Training Loss 92.16160541772842
2022-03-08 22:56:19,676 Epoch 8: Training Loss 87.1273393034935
2022-03-08 22:56:29,194 Epoch 9: Training Loss 83.28891712427139
2022-03-08 22:56:38,672 Epoch 10: Training Loss 80.31048119068146
2022-03-08 22:56:48,053 Epoch 11: Training Loss 77.99548625946045
2022-03-08 22:56:57,404 Epoch 12: Training Loss 75.94031345844269
2022-03-08 22:57:06,761 Epoch 13: Training Loss 74.25358979403973
2022-03-08 22:57:16,173 Epoch 14: Training Loss 72.90480993688107
2022-03-08 22:57:25,535 Epoch 15: Training Loss 71.66414198279381
2022-03-08 22:57:34,893 Epoch 16: Training Loss 70.51275759935379
2022-03-08 22:57:44,248 Epoch 17: Training Loss 69.55817425251007
2022-03-08 22:57:53,602 Epoch 18: Training Loss 68.7911030203104
2022-03-08 22:58:02,957 Epoch 19: Training Loss 67.95036913454533
2022-03-08 22:58:02,957 
RESULTS ON TEST DATA:
2022-03-08 22:58:04,275 	     precision: 0.9032
2022-03-08 22:58:04,275 	        recall: 0.9003
2022-03-08 22:58:04,275 	            F1: 0.8979
2022-03-08 22:58:04,275 	      accuracy: 0.9008
