2022-03-07 20:47:09,848 Epoch 0: Training Loss 559.8116536140442, Validation Loss 93.08761596679688
2022-03-07 20:49:22,596 Epoch 1: Training Loss 493.6191906929016, Validation Loss 75.4456787109375
2022-03-07 20:51:36,215 Epoch 2: Training Loss 429.8006491661072, Validation Loss 59.520606994628906
2022-03-07 20:53:51,561 Epoch 3: Training Loss 378.88801646232605, Validation Loss 47.33466339111328
2022-03-07 20:56:06,090 Epoch 4: Training Loss 343.418497800827, Validation Loss 38.832786560058594
2022-03-07 20:58:18,648 Epoch 5: Training Loss 320.386101603508, Validation Loss 33.006507873535156
2022-03-07 21:00:26,478 Epoch 6: Training Loss 305.5922507047653, Validation Loss 28.9477481842041
2022-03-07 21:02:37,276 Epoch 7: Training Loss 296.28426575660706, Validation Loss 26.070049285888672
2022-03-07 21:04:49,843 Epoch 8: Training Loss 290.34439063072205, Validation Loss 23.97390365600586
2022-03-07 21:07:01,610 Epoch 9: Training Loss 286.62698566913605, Validation Loss 22.319494247436523
2022-03-07 21:09:10,962 Epoch 10: Training Loss 284.0744295120239, Validation Loss 21.065494537353516
2022-03-07 21:11:16,915 Epoch 11: Training Loss 282.69319581985474, Validation Loss 20.034160614013672
2022-03-07 21:13:24,436 Epoch 12: Training Loss 281.84002566337585, Validation Loss 19.187278747558594
2022-03-07 21:15:32,772 Epoch 13: Training Loss 281.4468050003052, Validation Loss 18.49734878540039
2022-03-07 21:17:39,653 Epoch 14: Training Loss 281.46334993839264, Validation Loss 17.897104263305664
2022-03-07 21:19:46,341 Epoch 15: Training Loss 281.5487495660782, Validation Loss 17.414670944213867
2022-03-07 21:21:54,218 Epoch 16: Training Loss 281.8969006538391, Validation Loss 16.955947875976562
2022-03-07 21:24:04,116 Epoch 17: Training Loss 282.36039984226227, Validation Loss 16.5283260345459
2022-03-07 21:26:18,430 Epoch 18: Training Loss 282.93877279758453, Validation Loss 16.1799373626709
2022-03-07 21:28:29,129 Epoch 19: Training Loss 283.54489719867706, Validation Loss 15.838008880615234
2022-03-07 21:30:35,827 Epoch 20: Training Loss 284.30592262744904, Validation Loss 15.520548820495605
2022-03-07 21:32:43,241 Epoch 21: Training Loss 285.0529395341873, Validation Loss 15.299920082092285
2022-03-07 21:34:50,402 Epoch 22: Training Loss 285.9034022092819, Validation Loss 15.015345573425293
2022-03-07 21:37:03,242 Epoch 23: Training Loss 286.66126906871796, Validation Loss 14.796689987182617
2022-03-07 21:39:10,437 Epoch 24: Training Loss 287.41274893283844, Validation Loss 14.54946231842041
2022-03-07 21:41:16,802 Epoch 25: Training Loss 288.3064761161804, Validation Loss 14.365106582641602
2022-03-07 21:43:23,396 Epoch 26: Training Loss 289.15207040309906, Validation Loss 14.163272857666016
2022-03-07 21:45:29,354 Epoch 27: Training Loss 290.0524432659149, Validation Loss 13.947614669799805
2022-03-07 21:47:36,025 Epoch 28: Training Loss 290.87002742290497, Validation Loss 13.793832778930664
2022-03-07 21:49:42,174 Epoch 29: Training Loss 291.7559300661087, Validation Loss 13.619312286376953
2022-03-07 21:51:47,836 Epoch 30: Training Loss 292.6406989097595, Validation Loss 13.473280906677246
2022-03-07 21:53:54,679 Epoch 31: Training Loss 293.47592759132385, Validation Loss 13.31483268737793
2022-03-07 21:56:01,324 Epoch 32: Training Loss 294.3530008792877, Validation Loss 13.185620307922363
2022-03-07 21:58:08,335 Epoch 33: Training Loss 295.41277956962585, Validation Loss 13.04930591583252
2022-03-07 22:00:14,021 Epoch 34: Training Loss 296.1717814207077, Validation Loss 12.887519836425781
2022-03-07 22:02:20,283 Epoch 35: Training Loss 297.0347579717636, Validation Loss 12.780526161193848
2022-03-07 22:04:26,792 Epoch 36: Training Loss 297.94511580467224, Validation Loss 12.640436172485352
2022-03-07 22:06:34,728 Epoch 37: Training Loss 298.7454785108566, Validation Loss 12.531518936157227
2022-03-07 22:08:42,351 Epoch 38: Training Loss 299.63188123703003, Validation Loss 12.393488883972168
2022-03-07 22:10:49,721 Epoch 39: Training Loss 300.52809882164, Validation Loss 12.299789428710938
2022-03-07 22:12:56,601 Epoch 40: Training Loss 301.43029522895813, Validation Loss 12.188721656799316
2022-03-07 22:15:04,213 Epoch 41: Training Loss 302.3223686218262, Validation Loss 12.054479598999023
2022-03-07 22:17:11,120 Epoch 42: Training Loss 303.14941120147705, Validation Loss 11.95980167388916
2022-03-07 22:19:18,931 Epoch 43: Training Loss 304.071280002594, Validation Loss 11.871466636657715
2022-03-07 22:21:26,075 Epoch 44: Training Loss 304.85439813137054, Validation Loss 11.751840591430664
2022-03-07 22:23:32,211 Epoch 45: Training Loss 305.76846516132355, Validation Loss 11.657288551330566
2022-03-07 22:25:39,188 Epoch 46: Training Loss 306.55507349967957, Validation Loss 11.545451164245605
2022-03-07 22:27:47,041 Epoch 47: Training Loss 307.4372099637985, Validation Loss 11.463889122009277
2022-03-07 22:29:54,261 Epoch 48: Training Loss 308.2766555547714, Validation Loss 11.357818603515625
2022-03-07 22:32:01,609 Epoch 49: Training Loss 309.16893339157104, Validation Loss 11.274700164794922
2022-03-07 22:32:01,611 
RESULTS ON TEST DATA:
2022-03-07 22:32:04,066 	     precision: 0.9045
2022-03-07 22:32:04,066 	        recall: 0.9026
2022-03-07 22:32:04,066 	            F1: 0.9010
2022-03-07 22:32:04,066 	      accuracy: 0.9042
