2022-03-02 23:13:44,229 Train loader size: 188, Validation loader size: 47, Test loader size: 40
2022-03-02 23:17:46,886 Epoch 0: Training Loss 40.85072077438235
2022-03-02 23:21:48,566 Epoch 1: Training Loss 12.421701516956091
2022-03-02 23:25:50,624 Epoch 2: Training Loss 8.631280861794949
2022-03-02 23:29:52,701 Epoch 3: Training Loss 8.147594175767154
2022-03-02 23:33:55,816 Epoch 4: Training Loss 6.874858165858313
2022-03-02 23:38:09,216 Epoch 5: Training Loss 5.014398796018213
2022-03-02 23:42:24,350 Epoch 6: Training Loss 4.8958533285185695
2022-03-02 23:46:54,939 Epoch 7: Training Loss 4.719935820787214
2022-03-02 23:51:26,014 Epoch 8: Training Loss 4.297117342823185
2022-03-02 23:55:55,172 Epoch 9: Training Loss 3.8609781123232096
2022-03-03 00:00:22,494 Epoch 10: Training Loss 3.4246392526547424
2022-03-03 00:04:45,652 Epoch 11: Training Loss 3.456237125210464
2022-03-03 00:09:06,863 Epoch 12: Training Loss 3.29340781935025
2022-03-03 00:13:28,029 Epoch 13: Training Loss 3.251008245977573
2022-03-03 00:17:49,240 Epoch 14: Training Loss 2.496429028120474
2022-03-03 00:22:05,942 Epoch 15: Training Loss 2.5816284634784097
2022-03-03 00:26:26,603 Epoch 16: Training Loss 4.755696097447071
2022-03-03 00:30:46,942 Epoch 17: Training Loss 2.356122527999105
2022-03-03 00:35:07,257 Epoch 18: Training Loss 1.9026297147065634
2022-03-03 00:39:28,143 Epoch 19: Training Loss 2.2421992500749184
2022-03-03 00:39:28,143 
RESULTS ON TEST DATA:
2022-03-03 00:39:35,349 	     precision: 0.9897
2022-03-03 00:39:35,349 	        recall: 0.9898
2022-03-03 00:39:35,349 	            F1: 0.9895
2022-03-03 00:39:35,350 	      accuracy: 0.9896
