2022-03-08 22:43:18,860 Train loader size: 188, Validation loader size: 47, Test loader size: 40
2022-03-08 22:43:28,020 Epoch 0: Training Loss 420.3175456523895
2022-03-08 22:43:37,087 Epoch 1: Training Loss 281.21508824825287
2022-03-08 22:43:46,163 Epoch 2: Training Loss 140.53431805968285
2022-03-08 22:43:55,235 Epoch 3: Training Loss 99.02770897746086
2022-03-08 22:44:04,291 Epoch 4: Training Loss 83.37447226047516
2022-03-08 22:44:13,352 Epoch 5: Training Loss 75.24046379327774
2022-03-08 22:44:22,420 Epoch 6: Training Loss 70.25725683569908
2022-03-08 22:44:31,476 Epoch 7: Training Loss 66.94871407747269
2022-03-08 22:44:40,534 Epoch 8: Training Loss 64.59392367303371
2022-03-08 22:44:49,591 Epoch 9: Training Loss 62.78506751358509
2022-03-08 22:44:58,641 Epoch 10: Training Loss 61.31949508190155
2022-03-08 22:45:07,696 Epoch 11: Training Loss 60.266522631049156
2022-03-08 22:45:16,803 Epoch 12: Training Loss 59.212093979120255
2022-03-08 22:45:25,915 Epoch 13: Training Loss 58.345735400915146
2022-03-08 22:45:35,034 Epoch 14: Training Loss 57.68605937063694
2022-03-08 22:45:44,092 Epoch 15: Training Loss 57.04842655360699
2022-03-08 22:45:53,155 Epoch 16: Training Loss 56.45407246053219
2022-03-08 22:46:02,209 Epoch 17: Training Loss 55.96564853191376
2022-03-08 22:46:11,265 Epoch 18: Training Loss 55.54308806359768
2022-03-08 22:46:20,316 Epoch 19: Training Loss 55.14043487608433
2022-03-08 22:46:20,317 
RESULTS ON TEST DATA:
2022-03-08 22:46:21,621 	     precision: 0.9193
2022-03-08 22:46:21,621 	        recall: 0.9177
2022-03-08 22:46:21,621 	            F1: 0.9156
2022-03-08 22:46:21,621 	      accuracy: 0.9185
