2022-03-08 22:38:10,937 Train loader size: 188, Validation loader size: 47, Test loader size: 40
2022-03-08 22:38:20,412 Epoch 0: Training Loss 433.11290526390076
2022-03-08 22:38:29,838 Epoch 1: Training Loss 429.56103134155273
2022-03-08 22:38:39,261 Epoch 2: Training Loss 338.0286034345627
2022-03-08 22:38:48,680 Epoch 3: Training Loss 182.86785072088242
2022-03-08 22:38:58,235 Epoch 4: Training Loss 129.44500294327736
2022-03-08 22:39:07,829 Epoch 5: Training Loss 109.89007511734962
2022-03-08 22:39:17,369 Epoch 6: Training Loss 99.26439091563225
2022-03-08 22:39:26,880 Epoch 7: Training Loss 92.16160541772842
2022-03-08 22:39:36,365 Epoch 8: Training Loss 87.1273393034935
2022-03-08 22:39:45,899 Epoch 9: Training Loss 83.28891712427139
2022-03-08 22:39:55,435 Epoch 10: Training Loss 80.31048119068146
2022-03-08 22:40:04,907 Epoch 11: Training Loss 77.99548625946045
2022-03-08 22:40:14,368 Epoch 12: Training Loss 75.94031345844269
2022-03-08 22:40:24,024 Epoch 13: Training Loss 74.25358979403973
2022-03-08 22:40:33,639 Epoch 14: Training Loss 72.90480993688107
2022-03-08 22:40:43,405 Epoch 15: Training Loss 71.66414198279381
2022-03-08 22:40:53,071 Epoch 16: Training Loss 70.51275759935379
2022-03-08 22:41:02,919 Epoch 17: Training Loss 69.55817425251007
2022-03-08 22:41:12,833 Epoch 18: Training Loss 68.7911030203104
2022-03-08 22:41:22,586 Epoch 19: Training Loss 67.95036913454533
2022-03-08 22:41:22,586 
RESULTS ON TEST DATA:
2022-03-08 22:41:23,950 	     precision: 0.9032
2022-03-08 22:41:23,951 	        recall: 0.9003
2022-03-08 22:41:23,951 	            F1: 0.8979
2022-03-08 22:41:23,951 	      accuracy: 0.9008
